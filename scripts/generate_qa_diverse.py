# -*- coding: utf-8 -*-
"""
Q&A ë‹¤ì–‘í™” + ì¶”ê°€ ìƒì„±
ê¸°ì¡´ Q&Aì˜ ì§ˆë¬¸ì„ ë‹¤ì–‘í•œ í‘œí˜„ìœ¼ë¡œ í™•ì¥í•˜ê³ , ì¶”ê°€ ê·œê²©ì—ì„œ ìƒˆ Q&A ìƒì„±
"""

import json
import sys
import io
import os
import time
from pathlib import Path
from datetime import datetime

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

BASE_DIR = Path(__file__).parent.parent

# ============================================================
# ì¶”ê°€ ê·œê²© (2ë‹¨ê³„ í™•ì¥)
# ============================================================

ADDITIONAL_DOCUMENTS = {
    "kdb": [
        # RF Exposure (ë‹¤ì‹œ ì¶”ê°€)
        "KDB_935210",      # RF Exposure ì¼ë°˜
        "KDB_447498",      # RF Exposure KDB
        "KDB_648474",      # SAR ì¸¡ì •

        # ì¶”ê°€ KDB
        "KDB_784748",      # Bluetooth
        "KDB_941225",      # Power measurement
    ],
    "ecfr": [
        # ì¶”ê°€ Part
        "CFR_Part_15B",    # Unintentional radiators
        "CFR_Part_18",     # ISM equipment
        "CFR_Part_15D",    # Unlicensed PCS
    ],
    "rss": [
        # RF Exposure (ë‹¤ì‹œ ì¶”ê°€)
        "RSS-102",         # RF Exposure

        # ì¶”ê°€ RSS
        "RSS-210",         # License-exempt (legacy)
        "RSS-310",         # License-exempt (newer)
    ]
}

# ì§ˆë¬¸ ë‹¤ì–‘í™” í”„ë¡¬í”„íŠ¸
DIVERSIFY_PROMPT = """ê¸°ì¡´ Q&Aë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°™ì€ ë‚´ìš©ì„ ë¬»ëŠ” **ë‹¤ë¥¸ í‘œí˜„ì˜ ì§ˆë¬¸**ì„ ìƒì„±í•˜ì„¸ìš”.

## ê¸°ì¡´ Q&A
Q: {question}
A: {answer}

## ìƒì„± ê·œì¹™
1. ê°™ì€ ë‹µë³€ì´ ë‚˜ì˜¤ëŠ” ë‹¤ë¥¸ ì§ˆë¬¸ í‘œí˜„ 3ê°œ ìƒì„±
2. í•œêµ­ì–´ 1ê°œ, ì˜ì–´ 1ê°œ, ê°„ëµí•œ í‘œí˜„ 1ê°œ
3. ì‹¤ë¬´ìê°€ ì‹¤ì œë¡œ ë¬¼ì–´ë³¼ ë§Œí•œ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„

## ì¶œë ¥ í˜•ì‹ (JSON)
```json
[
  {{"question": "í•œêµ­ì–´ ë‹¤ë¥¸ í‘œí˜„", "lang": "ko"}},
  {{"question": "English version of the question", "lang": "en"}},
  {{"question": "ê°„ëµí•œ í‘œí˜„ (ì˜ˆ: UNII-1 ì¶œë ¥?)", "lang": "short"}}
]
```

JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""

# ìƒˆ Q&A ìƒì„± í”„ë¡¬í”„íŠ¸
QA_GENERATION_PROMPT = """ë‹¹ì‹ ì€ FCC/ISED RF ì¸ì¦ ì‹œí—˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ê·œê²© ë¬¸ì„œë¥¼ ì½ê³ , RF ì¸ì¦ ì—”ì§€ë‹ˆì–´ê°€ ì‹¤ë¬´ì—ì„œ ë¬¼ì–´ë³¼ ë§Œí•œ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.

## ê·œê²© ë¬¸ì„œ
{document}

## ì¶œì²˜ ì •ë³´
- ë¬¸ì„œ ID: {doc_id}
- ë¬¸ì„œ ìœ í˜•: {source_type}

## ìƒì„± ê·œì¹™
1. ì‹¤ë¬´ì—ì„œ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ìœ„ì£¼ë¡œ ìƒì„±
2. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì¡°ê±´, ì¸¡ì • ë°©ë²• ê´€ë ¨ ì§ˆë¬¸
3. ë‹µë³€ì—ëŠ” ë°˜ë“œì‹œ ê·¼ê±° ì¡°í•­/ì„¹ì…˜ í¬í•¨
4. í•œêµ­ì–´ë¡œ ì‘ì„±

## ì¶œë ¥ í˜•ì‹ (JSON)
```json
[
  {{
    "question": "ì§ˆë¬¸ ë‚´ìš©",
    "answer": "ë‹µë³€ ë‚´ìš© (ì¡°í•­ ë²ˆí˜¸ í¬í•¨)",
    "category": "ì¹´í…Œê³ ë¦¬"
  }}
]
```

3-5ê°œì˜ Q&Aë¥¼ ìƒì„±í•˜ì„¸ìš”. JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""


def get_claude_client():
    """Claude API í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    try:
        from anthropic import Anthropic

        api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not api_key:
            env_file = BASE_DIR / ".env"
            if env_file.exists():
                with open(env_file, 'r') as f:
                    for line in f:
                        if line.startswith("ANTHROPIC_API_KEY="):
                            api_key = line.split("=", 1)[1].strip().strip('"\'')
                            break

        if not api_key:
            print("âŒ ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None

        return Anthropic(api_key=api_key)
    except ImportError:
        print("âŒ anthropic íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None


def load_existing_qa():
    """ê¸°ì¡´ Q&A ë¡œë“œ"""
    qa_file = BASE_DIR / "aidata" / "qa_pairs.json"
    if qa_file.exists():
        with open(qa_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        return data.get('qa_pairs', [])
    return []


def diversify_questions(client, qa_pairs, max_items=50):
    """ê¸°ì¡´ Q&Aì˜ ì§ˆë¬¸ì„ ë‹¤ì–‘í™”"""
    print("\nğŸ“ ì§ˆë¬¸ ë‹¤ì–‘í™” ì¤‘...")

    diversified = []

    # ìƒìœ„ Nê°œ Q&Aë§Œ ë‹¤ì–‘í™” (ë¹„ìš© ì ˆê°)
    for i, qa in enumerate(qa_pairs[:max_items]):
        print(f"   [{i+1}/{min(len(qa_pairs), max_items)}] {qa['question'][:30]}...", end=" ")

        prompt = DIVERSIFY_PROMPT.format(
            question=qa['question'],
            answer=qa['answer']
        )

        try:
            response = client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=500,
                messages=[{"role": "user", "content": prompt}]
            )

            response_text = response.content[0].text

            # JSON íŒŒì‹±
            if "```json" in response_text:
                json_str = response_text.split("```json")[1].split("```")[0]
            elif "```" in response_text:
                json_str = response_text.split("```")[1].split("```")[0]
            else:
                json_str = response_text

            new_questions = json.loads(json_str.strip())

            # ìƒˆ ì§ˆë¬¸ë“¤ ì¶”ê°€ (ê°™ì€ ë‹µë³€ ê³µìœ )
            for new_q in new_questions:
                diversified.append({
                    'question': new_q['question'],
                    'answer': qa['answer'],
                    'category': qa.get('category', '') + f"_{new_q.get('lang', 'var')}",
                    'source_doc_id': qa.get('source_doc_id', ''),
                    'source_type': qa.get('source_type', ''),
                    'source_file': qa.get('source_file', ''),
                    'is_diversified': True,
                    'original_question': qa['question']
                })

            print(f"âœ“ +{len(new_questions)}ê°œ")

        except Exception as e:
            print(f"âœ— {e}")

        time.sleep(0.3)

    return diversified


def get_key_chunks(collection_name: str, doc_patterns: list, max_per_doc: int = 2):
    """í•µì‹¬ ë¬¸ì„œì—ì„œ ì²­í¬ ê°€ì ¸ì˜¤ê¸°"""
    import chromadb

    client = chromadb.PersistentClient(path=str(BASE_DIR / "aidata" / "vector_db"))

    col_map = {
        "kdb": "fcc_kdb",
        "ecfr": "fcc_ecfr",
        "rss": "ised_rss"
    }

    col_name = col_map.get(collection_name)
    if not col_name:
        return []

    try:
        collection = client.get_collection(col_name)
    except:
        return []

    all_docs = collection.get(include=['documents', 'metadatas'])

    chunks = []
    for pattern in doc_patterns:
        matched = []
        for i, doc_id in enumerate(all_docs['ids']):
            if pattern.lower() in doc_id.lower():
                matched.append({
                    'id': doc_id,
                    'content': all_docs['documents'][i],
                    'metadata': all_docs['metadatas'][i] if all_docs['metadatas'] else {}
                })

        for chunk in matched[:max_per_doc]:
            chunks.append({
                'doc_id': chunk['id'],
                'content': chunk['content'][:2000],
                'source_type': collection_name,
                'source_file': chunk['metadata'].get('source_file', pattern)
            })

    return chunks


def generate_new_qa(client, chunks):
    """ìƒˆ ë¬¸ì„œì—ì„œ Q&A ìƒì„±"""
    print("\nğŸ“„ ì¶”ê°€ ë¬¸ì„œì—ì„œ Q&A ìƒì„± ì¤‘...")

    new_qa = []

    for i, chunk in enumerate(chunks):
        print(f"   [{i+1}/{len(chunks)}] {chunk['doc_id'][:40]}...", end=" ")

        prompt = QA_GENERATION_PROMPT.format(
            document=chunk['content'],
            doc_id=chunk['doc_id'],
            source_type=chunk['source_type'].upper()
        )

        try:
            response = client.messages.create(
                model="claude-3-5-haiku-20241022",
                max_tokens=1500,
                messages=[{"role": "user", "content": prompt}]
            )

            response_text = response.content[0].text

            if "```json" in response_text:
                json_str = response_text.split("```json")[1].split("```")[0]
            elif "```" in response_text:
                json_str = response_text.split("```")[1].split("```")[0]
            else:
                json_str = response_text

            qa_pairs = json.loads(json_str.strip())

            for qa in qa_pairs:
                qa['source_doc_id'] = chunk['doc_id']
                qa['source_type'] = chunk['source_type']
                qa['source_file'] = chunk['source_file']

            new_qa.extend(qa_pairs)
            print(f"âœ“ {len(qa_pairs)}ê°œ")

        except Exception as e:
            print(f"âœ— {e}")

        time.sleep(0.5)

    return new_qa


def main():
    print("=" * 60)
    print("Q&A ë‹¤ì–‘í™” + í™•ì¥ (ëª©í‘œ: 420ê°œ)")
    print("=" * 60)

    client = get_claude_client()
    if not client:
        return

    # 1. ê¸°ì¡´ Q&A ë¡œë“œ
    existing_qa = load_existing_qa()
    print(f"\nğŸ“Š ê¸°ì¡´ Q&A: {len(existing_qa)}ê°œ")

    # 2. ì§ˆë¬¸ ë‹¤ì–‘í™” (ê¸°ì¡´ Q&Aì˜ 50ê°œë¥¼ ë‹¤ì–‘í™” â†’ +150ê°œ ì˜ˆìƒ)
    diversified_qa = diversify_questions(client, existing_qa, max_items=50)
    print(f"   â†’ ë‹¤ì–‘í™”ëœ Q&A: +{len(diversified_qa)}ê°œ")

    # 3. ì¶”ê°€ ë¬¸ì„œì—ì„œ ìƒˆ Q&A ìƒì„±
    all_new_qa = []
    for source_type, doc_patterns in ADDITIONAL_DOCUMENTS.items():
        print(f"\nğŸ“ {source_type.upper()} ì¶”ê°€ ë¬¸ì„œ...")
        chunks = get_key_chunks(source_type, doc_patterns, max_per_doc=2)
        print(f"   {len(chunks)}ê°œ ì²­í¬")

        new_qa = generate_new_qa(client, chunks)
        all_new_qa.extend(new_qa)

    print(f"\n   â†’ ìƒˆ Q&A: +{len(all_new_qa)}ê°œ")

    # 4. ì „ì²´ ë³‘í•©
    final_qa = existing_qa + diversified_qa + all_new_qa

    # 5. ì €ì¥
    output_file = BASE_DIR / "aidata" / "qa_pairs.json"
    output_data = {
        "generated_at": datetime.now().isoformat(),
        "total_qa_pairs": len(final_qa),
        "breakdown": {
            "original": len(existing_qa),
            "diversified": len(diversified_qa),
            "new_documents": len(all_new_qa)
        },
        "qa_pairs": final_qa
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 60)
    print(f"âœ… ì™„ë£Œ!")
    print(f"   - ê¸°ì¡´ Q&A: {len(existing_qa)}ê°œ")
    print(f"   - ë‹¤ì–‘í™”: +{len(diversified_qa)}ê°œ")
    print(f"   - ìƒˆ ë¬¸ì„œ: +{len(all_new_qa)}ê°œ")
    print(f"   - ì´í•©: {len(final_qa)}ê°œ")
    print(f"   - ì €ì¥: {output_file}")
    print("=" * 60)


if __name__ == "__main__":
    main()
