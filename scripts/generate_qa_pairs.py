# -*- coding: utf-8 -*-
"""
í•µì‹¬ ê·œê²© ë¬¸ì„œì—ì„œ Q&A ìŒ ìë™ ìƒì„±
Claude APIë¥¼ ì‚¬ìš©í•˜ì—¬ Synthetic Q&A ë°ì´í„° ìƒì„±
"""

import json
import sys
import os
import time
import io
from pathlib import Path
from datetime import datetime

# Windows ì½˜ì†” ì¸ì½”ë”© ì„¤ì •
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(BASE_DIR / "scripts"))

# ============================================================
# í•µì‹¬ ê·œê²© ì •ì˜ (RF ì¸ì¦ì—ì„œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ë¬¸ì„œ)
# ============================================================

KEY_DOCUMENTS = {
    "kdb": [
        # WLAN / Wi-Fi
        "KDB_905462",      # U-NII (5GHz WLAN) ì¸¡ì • ì ˆì°¨ - ë§¤ìš° ì¤‘ìš”
        "KDB_996369",      # 6GHz U-NII ê·œì¹™ - ì‹ ê·œ ì¤‘ìš”
        "KDB_388624",      # DFS í…ŒìŠ¤íŠ¸ ê°€ì´ë˜ìŠ¤
        "KDB_248227",      # 15.247 DTS ê°€ì´ë˜ìŠ¤
        "KDB_558074",      # WLAN ì¸¡ì • ê´€ë ¨

        # ê¸°íƒ€ ë¬´ì„ 
        "KDB_393764",      # UWB ê°€ì´ë˜ìŠ¤
        "KDB_273109",      # WWAN Part 22/24/27
        "KDB_789033",      # Short-range devices
        "KDB_987594",      # Low power ë¬´ì„ 
    ],
    "ecfr": [
        # Part 15 (ë¹„ì¸ê°€ ê¸°ê¸°)
        "CFR_Part_15C",    # 15.247 - Spread Spectrum, DTS
        "CFR_Part_15E",    # U-NII (5GHz, 6GHz WLAN)

        # ì´ë™í†µì‹ 
        "CFR_Part_22",     # Cellular
        "CFR_Part_24",     # PCS (ì£¼ìš”!)
        "CFR_Part_27",     # Misc Wireless

        # ê¸°íƒ€
        "CFR_Part_2",      # ì¼ë°˜ ê·œì •, RF Exposure
    ],
    "rss": [
        # í•µì‹¬ RSS
        "RSS-247",         # Low-power (15.247 ëŒ€ì‘) - í•µì‹¬!
        "RSS-GEN",         # General requirements - í•„ìˆ˜

        # íŠ¹ì • ê¸°ìˆ 
        "RSS-248",         # Digital transmission
        "RSS-199",         # Broadband (WWAN ëŒ€ì‘)
        "RSS-220",         # UWB
        "RSS-191",         # LMC systems
    ]
}

# Q&A ìƒì„± í”„ë¡¬í”„íŠ¸
QA_GENERATION_PROMPT = """ë‹¹ì‹ ì€ FCC/ISED RF ì¸ì¦ ì‹œí—˜ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ê·œê²© ë¬¸ì„œë¥¼ ì½ê³ , RF ì¸ì¦ ì—”ì§€ë‹ˆì–´ê°€ ì‹¤ë¬´ì—ì„œ ë¬¼ì–´ë³¼ ë§Œí•œ ì§ˆë¬¸ê³¼ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.

## ê·œê²© ë¬¸ì„œ
{document}

## ì¶œì²˜ ì •ë³´
- ë¬¸ì„œ ID: {doc_id}
- ë¬¸ì„œ ìœ í˜•: {source_type}

## ìƒì„± ê·œì¹™
1. ì‹¤ë¬´ì—ì„œ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ ìœ„ì£¼ë¡œ ìƒì„±
2. êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì¡°ê±´, ì¸¡ì • ë°©ë²• ê´€ë ¨ ì§ˆë¬¸
3. ë‹µë³€ì—ëŠ” ë°˜ë“œì‹œ ê·¼ê±° ì¡°í•­/ì„¹ì…˜ í¬í•¨
4. í•œêµ­ì–´ë¡œ ì‘ì„±

## ì¶œë ¥ í˜•ì‹ (JSON)
```json
[
  {{
    "question": "UNII-1 ëŒ€ì—­ì˜ ìµœëŒ€ ì¶œë ¥ ì œí•œì€?",
    "answer": "UNII-1 (5.15-5.25 GHz) ëŒ€ì—­ì˜ ìµœëŒ€ ì¶œë ¥ì€ 1W EIRPì…ë‹ˆë‹¤. ë‹¨, ì‹¤ë‚´ ì „ìš©ìœ¼ë¡œ ì œí•œë©ë‹ˆë‹¤. (Â§ 15.407(a)(1))",
    "category": "ì¶œë ¥ì œí•œ"
  }},
  {{
    "question": "...",
    "answer": "...",
    "category": "..."
  }}
]
```

3-5ê°œì˜ Q&Aë¥¼ ìƒì„±í•˜ì„¸ìš”. JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
"""


def get_claude_client():
    """Claude API í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    try:
        from anthropic import Anthropic

        api_key = os.environ.get("ANTHROPIC_API_KEY")
        if not api_key:
            # .env íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„
            env_file = BASE_DIR / ".env"
            if env_file.exists():
                with open(env_file, 'r') as f:
                    for line in f:
                        if line.startswith("ANTHROPIC_API_KEY="):
                            api_key = line.split("=", 1)[1].strip().strip('"\'')
                            break

        if not api_key:
            print("âŒ ANTHROPIC_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            print("   í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” .env íŒŒì¼ì— ì„¤ì •í•´ì£¼ì„¸ìš”.")
            return None

        return Anthropic(api_key=api_key)
    except ImportError:
        print("âŒ anthropic íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   pip install anthropic")
        return None


def get_key_chunks(collection_name: str, doc_patterns: list, max_per_doc: int = 3):
    """í•µì‹¬ ë¬¸ì„œì—ì„œ ì²­í¬ ê°€ì ¸ì˜¤ê¸°"""
    import chromadb

    client = chromadb.PersistentClient(path=str(BASE_DIR / "aidata" / "vector_db"))

    # ì»¬ë ‰ì…˜ ì´ë¦„ ë§¤í•‘
    col_map = {
        "kdb": "fcc_kdb",
        "ecfr": "fcc_ecfr",
        "rss": "ised_rss"
    }

    col_name = col_map.get(collection_name)
    if not col_name:
        return []

    try:
        collection = client.get_collection(col_name)
    except:
        print(f"  âš ï¸ ì»¬ë ‰ì…˜ {col_name} ì—†ìŒ")
        return []

    # ì „ì²´ ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
    all_docs = collection.get(include=['documents', 'metadatas'])

    chunks = []
    for pattern in doc_patterns:
        # íŒ¨í„´ì— ë§ëŠ” ë¬¸ì„œ í•„í„°ë§
        matched = []
        for i, doc_id in enumerate(all_docs['ids']):
            if pattern.lower() in doc_id.lower():
                matched.append({
                    'id': doc_id,
                    'content': all_docs['documents'][i],
                    'metadata': all_docs['metadatas'][i] if all_docs['metadatas'] else {}
                })

        # ë¬¸ì„œë‹¹ ìµœëŒ€ Nê°œ ì²­í¬ë§Œ ì„ íƒ (ì•ë¶€ë¶„ ìœ„ì£¼ - ë³´í†µ í•µì‹¬ ë‚´ìš©)
        for chunk in matched[:max_per_doc]:
            chunks.append({
                'doc_id': chunk['id'],
                'content': chunk['content'][:2000],  # í† í° ì œí•œ
                'source_type': collection_name,
                'source_file': chunk['metadata'].get('source_file', pattern)
            })

    return chunks


def generate_qa_for_chunk(client, chunk: dict) -> list:
    """ë‹¨ì¼ ì²­í¬ì—ì„œ Q&A ìƒì„±"""
    prompt = QA_GENERATION_PROMPT.format(
        document=chunk['content'],
        doc_id=chunk['doc_id'],
        source_type=chunk['source_type'].upper()
    )

    try:
        response = client.messages.create(
            model="claude-3-5-haiku-20241022",  # ë¹„ìš© íš¨ìœ¨ì ì¸ Haiku ì‚¬ìš©
            max_tokens=1500,
            messages=[{"role": "user", "content": prompt}]
        )

        # JSON íŒŒì‹±
        response_text = response.content[0].text

        # JSON ë¸”ë¡ ì¶”ì¶œ
        if "```json" in response_text:
            json_str = response_text.split("```json")[1].split("```")[0]
        elif "```" in response_text:
            json_str = response_text.split("```")[1].split("```")[0]
        else:
            json_str = response_text

        qa_pairs = json.loads(json_str.strip())

        # ì¶œì²˜ ì •ë³´ ì¶”ê°€
        for qa in qa_pairs:
            qa['source_doc_id'] = chunk['doc_id']
            qa['source_type'] = chunk['source_type']
            qa['source_file'] = chunk['source_file']

        return qa_pairs

    except json.JSONDecodeError as e:
        print(f"    âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return []
    except Exception as e:
        print(f"    âš ï¸ API ì˜¤ë¥˜: {e}")
        return []


def main():
    print("=" * 60)
    print("Q&A ìŒ ìë™ ìƒì„± (í•µì‹¬ ê·œê²© ë¬¸ì„œ)")
    print("=" * 60)

    # Claude í´ë¼ì´ì–¸íŠ¸
    client = get_claude_client()
    if not client:
        return

    all_qa_pairs = []
    total_chunks = 0

    # ê° ì»¬ë ‰ì…˜ë³„ ì²˜ë¦¬
    for source_type, doc_patterns in KEY_DOCUMENTS.items():
        print(f"\nğŸ“ {source_type.upper()} ë¬¸ì„œ ì²˜ë¦¬ ì¤‘...")

        chunks = get_key_chunks(source_type, doc_patterns, max_per_doc=2)
        print(f"   {len(chunks)}ê°œ ì²­í¬ ì„ íƒë¨")

        for i, chunk in enumerate(chunks):
            print(f"   [{i+1}/{len(chunks)}] {chunk['doc_id'][:40]}...", end=" ")

            qa_pairs = generate_qa_for_chunk(client, chunk)

            if qa_pairs:
                all_qa_pairs.extend(qa_pairs)
                print(f"âœ“ {len(qa_pairs)}ê°œ Q&A ìƒì„±")
            else:
                print("âœ— ì‹¤íŒ¨")

            total_chunks += 1

            # Rate limit ë°©ì§€
            time.sleep(0.5)

    # ê²°ê³¼ ì €ì¥
    output_file = BASE_DIR / "aidata" / "qa_pairs.json"
    output_file.parent.mkdir(parents=True, exist_ok=True)

    output_data = {
        "generated_at": datetime.now().isoformat(),
        "total_qa_pairs": len(all_qa_pairs),
        "source_chunks": total_chunks,
        "qa_pairs": all_qa_pairs
    }

    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, ensure_ascii=False, indent=2)

    print("\n" + "=" * 60)
    print(f"âœ… ì™„ë£Œ!")
    print(f"   - ì²˜ë¦¬ëœ ì²­í¬: {total_chunks}ê°œ")
    print(f"   - ìƒì„±ëœ Q&A: {len(all_qa_pairs)}ê°œ")
    print(f"   - ì €ì¥ ìœ„ì¹˜: {output_file}")
    print("=" * 60)

    # ìƒ˜í”Œ ì¶œë ¥
    if all_qa_pairs:
        print("\nğŸ“ ìƒ˜í”Œ Q&A:")
        for qa in all_qa_pairs[:3]:
            print(f"\nQ: {qa['question']}")
            print(f"A: {qa['answer'][:100]}...")


if __name__ == "__main__":
    main()
