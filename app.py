"""
FCC/ISED ì¸ì¦ Q&A ì‹œìŠ¤í…œ - Web UI
Streamlit ê¸°ë°˜ ì›¹ ì¸í„°í˜ì´ìŠ¤
"""

import streamlit as st
import sys
import json
from pathlib import Path
from datetime import datetime

# ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent / "scripts"))

from rag_system import RAGSystem, MockLLMBackend, OllamaBackend, ClaudeBackend

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="FCC/ISED ì¸ì¦ Q&A",
    page_icon="ğŸ“¡",
    layout="wide"
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'rag_system' not in st.session_state:
    st.session_state.rag_system = None
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'last_response' not in st.session_state:
    st.session_state.last_response = None
if 'feedback_submitted' not in st.session_state:
    st.session_state.feedback_submitted = False

# í”¼ë“œë°± ì €ì¥ ê²½ë¡œ
FEEDBACK_FILE = Path(__file__).parent / "aidata" / "feedback.json"


def save_feedback(query: str, answer: str, sources: list, rating: int, comment: str):
    """í”¼ë“œë°± ì €ì¥"""
    feedback_data = {
        "timestamp": datetime.now().isoformat(),
        "query": query,
        "answer": answer[:500],  # ë‹µë³€ ì¼ë¶€ë§Œ ì €ì¥
        "sources": [{"doc_id": s.doc_id, "source_type": s.source_type} for s in sources[:3]],
        "rating": rating,
        "comment": comment
    }

    # ê¸°ì¡´ í”¼ë“œë°± ë¡œë“œ
    feedbacks = []
    if FEEDBACK_FILE.exists():
        try:
            with open(FEEDBACK_FILE, 'r', encoding='utf-8') as f:
                feedbacks = json.load(f)
        except:
            feedbacks = []

    # ìƒˆ í”¼ë“œë°± ì¶”ê°€
    feedbacks.append(feedback_data)

    # ì €ì¥
    FEEDBACK_FILE.parent.mkdir(parents=True, exist_ok=True)
    with open(FEEDBACK_FILE, 'w', encoding='utf-8') as f:
        json.dump(feedbacks, f, ensure_ascii=False, indent=2)

    return True


@st.cache_resource
def load_rag_system(backend_type: str = "mock", model: str = "qwen2:7b", api_key: str = None, use_reranker: bool = False):
    """RAG ì‹œìŠ¤í…œ ë¡œë“œ (ìºì‹±)"""
    from rag_system import VectorSearch

    # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™” (ë¦¬ë­ì»¤ ì˜µì…˜ í¬í•¨)
    search_engine = VectorSearch(use_reranker=use_reranker)

    if backend_type == "ollama":
        try:
            import requests
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                rag = RAGSystem(llm_backend=OllamaBackend(model=model))
                rag.search_engine = search_engine
                return rag
        except:
            st.warning("Ollama ì—°ê²° ì‹¤íŒ¨. Mock ëª¨ë“œë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
    elif backend_type == "claude":
        try:
            rag = RAGSystem(llm_backend=ClaudeBackend(api_key=api_key, model=model))
            rag.search_engine = search_engine
            return rag
        except Exception as e:
            st.error(f"Claude API ì˜¤ë¥˜: {e}")

    rag = RAGSystem(llm_backend=MockLLMBackend())
    rag.search_engine = search_engine
    return rag


def main():
    # í—¤ë”
    st.title("ğŸ“¡ FCC/ISED ì¸ì¦ Q&A ì‹œìŠ¤í…œ")
    st.markdown("---")

    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")

        # LLM ì„ íƒ
        llm_option = st.selectbox(
            "LLM ë°±ì—”ë“œ",
            [
                "Claude API (Sonnet)",
                "Claude API (Haiku)",
                "Ollama - Qwen2 (í•œêµ­ì–´)",
                "Ollama - Llama3 (ì˜ì–´)",
                "Mock (ê²€ìƒ‰ë§Œ)"
            ],
            help="Claude: ê³ í’ˆì§ˆ ë‹µë³€, Ollama: ë¡œì»¬ ë¬´ë£Œ"
        )

        # Claude API í‚¤ ì…ë ¥
        api_key = None
        if "Claude" in llm_option:
            api_key = st.text_input(
                "Claude API Key",
                type="password",
                help="sk-ant-... í˜•ì‹ì˜ API í‚¤",
                placeholder="sk-ant-api03-..."
            )
            if not api_key:
                st.warning("API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”")

        # ë°±ì—”ë“œ ì„¤ì •
        if "Claude" in llm_option:
            backend_type = "claude"
            if "Haiku" in llm_option:
                model = "claude-3-5-haiku-20241022"
            else:
                model = "claude-3-5-sonnet-20241022"
        elif "Ollama" in llm_option:
            backend_type = "ollama"
            model = "qwen2:7b" if "Qwen2" in llm_option else "llama3"
        else:
            backend_type = "mock"
            model = None

        # ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
        n_results = st.slider("ê²€ìƒ‰ ê²°ê³¼ ìˆ˜", 3, 10, 5)

        # ê²€ìƒ‰ ì˜µì…˜
        use_hybrid = st.checkbox("í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (BM25+Vector)", value=True,
                                 help="í‚¤ì›Œë“œ+ì˜ë¯¸ ê²€ìƒ‰ ê²°í•©. Part 15E ê°™ì€ ì •í™•í•œ ê²€ìƒ‰ì— íš¨ê³¼ì ")
        use_rerank = st.checkbox("ë¦¬ë­í‚¹ (CrossEncoder)", value=False,
                                 help="ê²€ìƒ‰ ê²°ê³¼ ì¬ì •ë ¬. ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼")

        # ì»¬ë ‰ì…˜ ì„ íƒ
        st.subheader("ê²€ìƒ‰ ëŒ€ìƒ")
        search_kdb = st.checkbox("FCC KDB", value=True)
        search_ecfr = st.checkbox("eCFR (47 CFR)", value=True)
        search_rss = st.checkbox("ISED RSS", value=True)
        search_testreport = st.checkbox("Test Reports", value=True)

        collections = []
        if search_kdb:
            collections.append("fcc_kdb")
        if search_ecfr:
            collections.append("fcc_ecfr")
        if search_rss:
            collections.append("ised_rss")
        if search_testreport:
            collections.append("fcc_testreport")

        st.markdown("---")
        st.markdown("""
        ### ğŸ“š ë°ì´í„° ì†ŒìŠ¤
        - **KDB**: 32ê°œ ë¬¸ì„œ (4,865 ì²­í¬)
        - **eCFR**: 17ê°œ Part (9,612 ì²­í¬)
        - **RSS**: 34ê°œ ê·œê²© (1,315 ì²­í¬)
        - **Test Reports**: 5ê°œ (807 ì²­í¬)
        """)

        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        if st.button("ğŸ”„ ì‹œìŠ¤í…œ ì¬ë¡œë“œ"):
            st.cache_resource.clear()
            st.rerun()

    # RAG ì‹œìŠ¤í…œ ë¡œë“œ
    with st.spinner("ì‹œìŠ¤í…œ ë¡œë”© ì¤‘..."):
        rag = load_rag_system(backend_type, model, api_key, use_rerank)

    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([2, 1])

    with col1:
        st.subheader("ğŸ’¬ ì§ˆë¬¸í•˜ê¸°")

        # ì§ˆë¬¸ ì…ë ¥
        query = st.text_input(
            "ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: DFS í…ŒìŠ¤íŠ¸ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜ìš”?",
            key="query_input"
        )

        # ì˜ˆì‹œ ì§ˆë¬¸
        st.markdown("**ì˜ˆì‹œ ì§ˆë¬¸:**")
        example_cols = st.columns(3)
        examples = [
            "DFS í…ŒìŠ¤íŠ¸ ì ˆì°¨",
            "ëª¨ë“ˆ ì¸ì¦ ìš”êµ¬ì‚¬í•­",
            "RF ë…¸ì¶œ ì œí•œ"
        ]
        for i, ex in enumerate(examples):
            if example_cols[i].button(ex, key=f"ex_{i}"):
                query = ex

        # ê²€ìƒ‰ ì‹¤í–‰
        if query:
            search_mode = "ê²€ìƒ‰ ì¤‘..."
            if use_hybrid and use_rerank:
                search_mode = "í•˜ì´ë¸Œë¦¬ë“œ + ë¦¬ë­í‚¹ ì¤‘..."
            elif use_hybrid:
                search_mode = "í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì¤‘..."
            elif use_rerank:
                search_mode = "ë¦¬ë­í‚¹ ê²€ìƒ‰ ì¤‘..."

            with st.spinner(search_mode):
                # Q&A ê²€ìƒ‰ ë¨¼ì €
                qa_matches = rag.search_engine.search_qa(query, n_results=2, threshold=0.5)

                # ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
                search_results = rag.search_engine.search(
                    query,
                    collections=collections if collections else None,
                    n_results=n_results,
                    hybrid=use_hybrid,
                    rerank=use_rerank
                )

            # Q&A ë§¤ì¹­ ê²°ê³¼ í‘œì‹œ
            if qa_matches:
                st.markdown("---")
                st.subheader("ğŸ’¡ ê´€ë ¨ Q&A (ê²€ì¦ëœ ë‹µë³€)")
                for i, qa in enumerate(qa_matches):
                    similarity = qa['similarity'] * 100
                    with st.expander(f"Q: {qa['question'][:60]}... ({similarity:.0f}% ë§¤ì¹­)", expanded=(i == 0)):
                        st.markdown(f"**ì§ˆë¬¸:** {qa['question']}")
                        st.markdown(f"**ë‹µë³€:** {qa['answer']}")
                        st.caption(f"ì¶œì²˜: {qa['source_doc_id']} | ì¹´í…Œê³ ë¦¬: {qa['category']}")

            # ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ
            st.markdown("---")
            st.subheader("ğŸ” ê²€ìƒ‰ ê²°ê³¼")

            if not search_results:
                st.warning("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                for i, result in enumerate(search_results):
                    similarity = (1 - result.distance) * 100

                    with st.expander(
                        f"[{i+1}] {result.doc_id} - ìœ ì‚¬ë„: {similarity:.1f}%",
                        expanded=(i == 0)
                    ):
                        st.markdown(f"**íŒŒì¼:** `{result.source_file}`")
                        st.markdown(f"**ìœ í˜•:** {result.source_type.upper()}")
                        st.markdown("**ë‚´ìš©:**")
                        st.text_area(
                            "content",
                            result.content,
                            height=150,
                            key=f"result_{i}",
                            label_visibility="collapsed"
                        )

                # LLM ë‹µë³€ (Ollama ë˜ëŠ” Claude ì‚¬ìš© ì‹œ)
                if backend_type in ["ollama", "claude"] and (backend_type != "claude" or api_key):
                    st.markdown("---")
                    st.subheader("ğŸ¤– AI ë‹µë³€")
                    with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
                        response = rag.ask(query, n_results=n_results)
                        st.markdown(response.answer)
                        st.session_state.last_response = response
                        st.session_state.feedback_submitted = False

                    # í”¼ë“œë°± UI
                    st.markdown("---")
                    st.subheader("ğŸ“ ë‹µë³€ í‰ê°€")

                    col_rating, col_comment = st.columns([1, 2])

                    with col_rating:
                        rating = st.radio(
                            "ë‹µë³€ í’ˆì§ˆ (1-5ì )",
                            options=[1, 2, 3, 4, 5],
                            format_func=lambda x: "â­" * x,
                            horizontal=True,
                            key="rating_input"
                        )

                    with col_comment:
                        comment = st.text_area(
                            "ì½”ë©˜íŠ¸ (ì„ íƒì‚¬í•­)",
                            placeholder="ì–´ë–¤ ì ì´ ì¢‹ì•˜ê±°ë‚˜ ë¶€ì¡±í–ˆë‚˜ìš”? ì›í•˜ëŠ” ë‹µë³€ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?",
                            height=80,
                            key="comment_input"
                        )

                    if st.button("âœ… í”¼ë“œë°± ì œì¶œ", type="primary"):
                        if st.session_state.last_response:
                            save_feedback(
                                query=query,
                                answer=response.answer,
                                sources=search_results,
                                rating=rating,
                                comment=comment
                            )
                            st.success(f"í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤! (í‰ì : {'â­' * rating})")
                            st.session_state.feedback_submitted = True

                elif backend_type == "claude" and not api_key:
                    st.warning("âš ï¸ Claude API í‚¤ë¥¼ ì…ë ¥í•´ì•¼ AI ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                else:
                    st.info("ğŸ’¡ AI ë‹µë³€ì„ ë³´ë ¤ë©´ Ollama ë˜ëŠ” Claude APIë¥¼ ì„ íƒí•˜ì„¸ìš”.")

    with col2:
        st.subheader("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ")

        # í†µê³„
        stats = {
            "KDB ë¬¸ì„œ": "32ê°œ KDB (4,865)",
            "eCFR": "17ê°œ Part (9,612)",
            "RSS": "34ê°œ ê·œê²© (1,315)",
            "Test Report": "5ê°œ (807)",
            "ì´ ì²­í¬": "16,599ê°œ"
        }

        for key, value in stats.items():
            st.metric(key, value)

        st.markdown("---")

        # ê²€ìƒ‰ íˆìŠ¤í† ë¦¬
        st.subheader("ğŸ“ ìµœê·¼ ê²€ìƒ‰")
        if query and query not in st.session_state.chat_history:
            st.session_state.chat_history.append(query)
            # ìµœê·¼ 10ê°œë§Œ ìœ ì§€
            st.session_state.chat_history = st.session_state.chat_history[-10:]

        for q in reversed(st.session_state.chat_history[-5:]):
            st.text(f"â€¢ {q}")


if __name__ == "__main__":
    main()
